# -*- coding: utf-8 -*-
"""Predictive Analysisi Project_Abraham.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gfxPKVlO0yf3O3E7OiUtyoMyxTN5D9oJ

# Analisis Prediktif: Prediksi Calon Pelanggan Asuransi Kendaraan yang Potensial dengan Waktu Secepatnya
---
Oleh: [Abraham Naiborhu](https://www.dicoding.com/users/abrahampn)

*Proyek Submission Satu - Machine Learning Terapan Dicoding*

---

##Pendahuluan
Proyek ini membahas topik asuransi yang dibuat untuk memprediksi calon pelanggan potensial yang tertarik untuk membeli asuransi kendaraan dan pelanggan tersebut sudah memiliki asuransi kesehatan. Dataset diambil dari url: https://www.kaggle.com/anmolkumar/health-insurance-cross-sell-prediction

## Mengimport pustaka/modul python yang dibutuhkan
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install opendatasets

import opendatasets as od
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

"""## Getting the dataset
Saat menggunakan Opendatasets, diharapkan pengguna menyiapkan kaggle (karena dataset dari kaggle) username dan kaggle key
"""

od.download("https://www.kaggle.com/anmolkumar/health-insurance-cross-sell-prediction")

df_train = ("/content/health-insurance-cross-sell-prediction/train.csv")
df_test = ("/content/health-insurance-cross-sell-prediction/test.csv")
sample = ("/content/health-insurance-cross-sell-prediction/sample_submission.csv")

"""##Data understanding
Bagian ini akan menjelaskan mengenai karakteristik dari dataset yang didapatkan

### Train Data
| Variable | Definition |
|----------|--------|
| id | Unique ID for the customer|
| Gender | Gender of the customer |
| Age | Age of the customer |
| Driving_License | 0 : Customer does not have DL, 1 : Customer already has DL|
| Region_Code | Unique code for the region of the customer |
| Previously_Insured | 1 : Customer already has Vehicle Insurance, 0 : Customer doesn't have Vehicle Insurance |
| Vehicle_Age | Age of the Vehicle |
| Vehicle_Damage | 1 : Customer got his/her vehicle damaged in the past. 0 : Customer didn't get his/her vehicle damaged in the past. |
| Annual_Premium | The amount customer needs to pay as premium in the year |
| PolicySalesChannel | Anonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc. |
| Vintage | Number of Days, Customer has been associated with the company |
| Response | 1 : Customer is interested, 0 : Customer is not interested |

### Test Data
| Variable | Definition |
|-----|-----|
| id | Unique ID for the customer|
| Gender | Gender of the customer |
| Age | Age of the customer |
| Driving_License | 0 : Customer does not have DL, 1 : Customer already has DL|
| Region_Code | Unique code for the region of the customer |
| Previously_Insured | 1 : Customer already has Vehicle Insurance, 0 : Customer doesn't have Vehicle Insurance |
| Vehicle_Age | Age of the Vehicle |
| Vehicle_Damage | 1 : Customer got his/her vehicle damaged in the past. 0 : Customer didn't get his/her vehicle damaged in the past. |
| Annual_Premium | The amount customer needs to pay as premium in the year |
| PolicySalesChannel | Anonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc. |

### Sample Data

| Variable | Definition |
|-----|-----|
| id | Unique ID for the customer|
| Response | 1 : Customer is interested, 0 : Customer is not interested |

## Dataset Checking
Di bagian ini, kita akan melihat secara langsung mengenai karakteristik datasetnya
"""

df_train = pd.read_csv(df_train) 
df_test = pd.read_csv(df_test)
sample = pd.read_csv(sample)

"""### All about df_train"""

df_train.info()

df_train

df_train.describe()

"""### All about df_test"""

df_test.info()

df_test.describe()

df_test

"""### All about sample"""

sample.info()

sample.describe()

sample

"""## Data Analysis
Di bagian ini kita akan menelusuri datanya dan melakukan data handling.

### Setting Up the Dataset

#### Handling missing values
"""

df_train.isnull().sum()

"""#### Handling unused variable
Disini kita akan drop ID karena itu tidak dibutukan dalam model ini
"""

df_train = df_train.drop('id', axis = 1)
df_train

df_train.shape

"""#### Handling Outliers
Outliers merupakan data yang memiliki karakteristik yang berbeda jauh dari data data lainnya. Data tipe ini dapat muncul dalam bentuk yang ekstrim. Oleh sebab itu, data semacam ini harus disaring dan dibuang.
"""

#Finding the numerical data
numerical_data = []
for i in df_train.columns:
  if(df_train.dtypes[i] == 'int64' or df_train[i].dtypes == 'float64'):
    numerical_data.append(i)
print(numerical_data)

#polishing the numerical data (kita akan mendrop data)
numerical_data.pop(1)
numerical_data.pop(-1)
print(numerical_data)

#Visualisasi box plot untuk mengecek outliers
for columns in numerical_data:
  sns.boxplot(df_train[columns])
  plt.show()

#Rumus dari IQR
#Batas bawah = Q1 - 1.5 * IQR
#Batas atas = Q3 + 1.5 * IQR

Q1 = df_train[numerical_data].quantile(0.25)
Q2 = df_train[numerical_data].quantile(0.5)
Q3 = df_train[numerical_data].quantile(0.75)
IQR = Q3 - Q1
df_train = df_train[~((df_train<(Q1-1.5*IQR))|(df_train>(Q3+1.5*IQR))).any(axis=1)]
df_train.shape

df_train

"""### Univariate Analysis"""

#Bagi feature menjadi dua set (Numerical dan categorical)
categorical_data = ['Gender','Driving_License',
         'Previously_Insured',
         'Vehicle_Age',
         'Vehicle_Damage']
numerical_data = ['Age','Region_Code',
         'Annual_Premium',
         'Policy_Sales_Channel',
         'Vintage']

#Categorical Feature
for i in categorical_data:
    sns.countplot(df_train[i], palette = 'Set3')
    plt.show()

sns.countplot(df_train['Response'], palette = 'Set3')
plt.show()

#Numerical feature
df_train.hist(bins=50, figsize=(20,15))
plt.show()

"""### Multivariate Analysis"""

#Hubungan antara categorical feature terhadap response
for col in categorical_data:
    sns.countplot(x = col, hue = 'Response', data = df_train)
    plt.show()

#Hubungan antara response, umur, dan gender
plt.figure(figsize = (12,5))
sns.violinplot(x = 'Response', y = 'Age', hue = 'Gender', data = df_train, palette = 'Set3')
plt.show()

"""Visualisasi diatas menjelaskan bahwa orang yang berumur 20 - 30 tahun memilih untuk tidak memberikan response, sedangkan yang berumur 40 - 50 memilih untuk mengatakan iya."""

#Numerical Fearure
sns.pairplot(df_train, diag_kind = 'kde')

"""Dengan ini, kita tau bawa data ini non-linear, sehingga kita akan menggunakan model yang dapat digunakan untuk klasifikasi non-linear"""

#Heat map untuk melihat korelasi antara feature satu dan feature lainnya
plt.figure(figsize = (10,8))
correlation_matrix = df_train.corr().round(2)
sns.heatmap(data = correlation_matrix, annot = True, cmap = 'coolwarm', linewidths = 0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size = 20)

"""Pada akhirnya kita akan meniadakan column: Region code, annual premium, vintage, dan driving liscense for the best result

## Data Preparation
Teknik yang akan digunakan untuk data preparation ini adalah:
1. One-hot-encoding data
2. Changing nama kolom agar dapat diterima oleh machine learning
3. Dropping feature yang kurang diperlukan
4. Splitting data
5. Standarizing data

###Encoding fitur kategori
"""

for col in categorical_data:
  df_train = pd.concat([df_train, pd.get_dummies(df_train[col], prefix = col, drop_first = True)], axis = 1)
  df_train = df_train.drop(col, axis = 1)

df_train

"""### Mengubah nama kolom"""

#Mengubah nama kolom agar dapat diproses oleh sistem
df_train.rename(columns = {"Vehicle_Age_< 1 Year": "Vehicle_Age_less_1_Year", "Vehicle_Age_> 2 Years": "Vehicle_Age_more_2_Years"}, inplace = True)
df_train.head()

"""### Droping feature yang kurang dibutuhkan
Jika ingin mengetahui feature yang kurang dibutuhkan, Anda dapat dilihat dari heat map diatas
"""

df_train = df_train.drop(['Region_Code', 'Annual_Premium', 'Vintage'], axis = 1)
df_train.head()

"""### Splitting data"""

from sklearn.model_selection import train_test_split
x = df_train.drop('Response',axis = 1)
y = df_train['Response']
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)

"""### Standarisasi data
standarisasi data menggunakan standarad scaler
"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler() 
scaler.fit(x_train) 
x_train = scaler.transform(x_train) 
x_test = scaler.transform(x_test)

"""##Model Training"""

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

#Decision Tree Model
from sklearn.tree import DecisionTreeClassifier

print("Decision Tree")
print("Confusion Matrix")
classifier = DecisionTreeClassifier()
classifier.fit(x_train, y_train)
pred = classifier.predict(x_test)
print(confusion_matrix(y_test, pred))
print(classification_report(y_test, pred))


from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, pred)
print("Accuracy            : {}".format(round(acc, 3)))

#Random Forest Tree Model
from sklearn.ensemble import RandomForestClassifier

print("Random Forest")
print("Confusion Matrix")
forest = RandomForestClassifier()
forest.fit(x_train, y_train)
pred = forest.predict(x_test)
print(confusion_matrix(y_test, pred))
print(classification_report(y_test, pred))


from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, pred)
print("Accuracy            : {}".format(round(acc, 3)))

#XGBoost Model
from xgboost import XGBClassifier

print("XGB")
print("Confusion Matrix")
XGB = XGBClassifier()
XGB.fit(x_train, y_train)
pred = XGB.predict(x_test)
print(confusion_matrix(y_test, pred))
print(classification_report(y_test, pred))

from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, pred)
print("Accuracy            : {}".format(round(acc, 3)))